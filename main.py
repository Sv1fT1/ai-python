import numpy as np


def f(x):
    return 2 / (1 + np.exp(-x)) - 1   #Гипербарический тангенс


def df(x):
    return 0.5 * (1 + x) * (1 - x)   #Производная


W1 = np.array([[-0.2, 0.3, -0.4], [0.1, -0.3, -0.4]]) # инициализация весов первого слоя
W2 = np.array([0.2, 0.3])                             # инициализация весов второго слоя


def go_forward(input):                           # Функция запуска НС
    sum = np.dot(W1, input)                      # Множим веса на входные данные нейрона
    out = np.array([f(x) for x in sum])          # Выходные значения нейронов

    sum = np.dot(W2, out)                        # Множим веса на входные значения 2 слоя (выходные значения 1 слоя)
    y = f(sum)                                   # Вычесляем выходные данные НС
    return y, out                                # Выводим output НС и выходные значения каждого нейрона


def train(epoch):                                                       # Функция обучения НС
    global W2, W1
    step = 0.01                                                         # Шаг обучения
    N = 10000                                                           # Количество итераций
    count = len(epoch)                                                  # Вычесляем размер обучающей выборки


    for k in range(N):
        x = epoch[np.random.randint(0, count)]                     # Выбераем случайный входной сигнал
        y, out = go_forward(x[0:3])                                     # Проводим данные через НС
        e = y - x[-1]                                                   # Вычесляем ошибку НС
        gradient = e * df(y)                                            # Вычесляем локальный градиент
        W2[0] = W2[0] - step * gradient * out[0]                        # Коректировка веса первой связи
        W2[1] = W2[1] - step * gradient * out[1]                        # Коректировка веса второй связи

        gradient2 = W2 * gradient * df(out)                             # Вектор из 2-х величин локальных градиентов

        # Коректировка связей первого слоя
        W1[0, :] = W1[0, :] - np.array(x[0:3]) * gradient2[0] * step
        W1[1, :] = W1[1, :] - np.array(x[0:3]) * gradient2[1] * step


epoch = [
    (-1, -1, -1, -1),
    (-1, -1, 1, 1),
    (-1, 1, -1, -1),
    (-1, 1, 1, 1),
    (1, -1, -1, -1),
    (1, -1, 1, 1),
    (1, 1, -1, -1),
    (1, 1, 1, -1)
]

train(epoch)                                                            # Старт тренеровки НС

for x in epoch:
    y, out = go_forward(x[0:3])
    print(f"Выходное значение НС: {y} => {x[-1]}")
